dataset:
  hf_dataset_id: Jackie2235/flickr30k_attn_ft

model:
  name: Qwen/Qwen3-VL-8B-Instruct
  trust_remote_code: true
  load_in_4bit: false
  lora_r: 8
  lora_alpha: 16
  lora_dropout: 0.05
  lora_target_modules: [q_proj, k_proj, v_proj, o_proj]
  attention_layers: []
  attention_heads: []

train:
  output_dir: checkpoints/qwen3_vl_8b_attn_ft_vacuum
  loss: vacuum
  loss_weight: 0.8
  seed: 42
  batch_size: 2
  num_epochs: 1
  max_steps: 16000
  lr: 1.0e-4
  weight_decay: 0.01
  warmup_steps: 200
  grad_accum_steps: 8
  mixed_precision: bf16
  log_every: 20
  save_every: 4000
  wandb_enabled: true
  wandb_project: attn_ft
  wandb_entity:
  wandb_run_name:
